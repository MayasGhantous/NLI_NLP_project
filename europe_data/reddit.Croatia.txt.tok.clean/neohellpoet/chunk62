  that basically means that as long as the enemy does n't nuke you , they 're free to do whatever they want . 
  you can try and build a system that 's less conservative about going off , but there 's an issue there as well . 
  nuclear annihilation is easy since the effects are quite extreme , but if you wanted to have the system go off when a foreign military crosses your border , now you have a few issues . 
  how does the system distinguish between civilians and military ? 
  can a foreign military abuse that distinction ? 
  does the system watch the whole continent or just the border ? 
  can the enemy travel by sea or underground and launch an attack ? 
  if you do n't make the system very , very conservative it 's very likely to get a false positive at some point and then you basically built a suicide box with an unknown timer . 
  if you do n't make it very liberal at interpreting a threat , the enemy will abuse any exceptions put in place . 
  also , any system that would need to process complex data is in and of it self a security back door an enemy could use to disable your defenses . 
  the concept is cute . 
  it essentially eliminates the human factor and makes launching a first strike very unappealing since you know for a fact you would be facing mass retaliation , but it 's not a defense against conventional war . 
  quite the opposite , you 're telling your enemy to hurry up and take over before the system can malfunction and nuke them . 
  it 's actually 10.4 % worldwide . 
  apple is an expensive , luxury brand with a narrow , wealthy audience . 
  android is the real issue here . 
  much like microsoft , while it 's somewhat open , thus allowing for anyone to put stuff on it , it 's basically all but guaranteed to get more restrictive with time . 
  we need a third option , preferably one that 's not in the hands of a foreign power . 
  it 's actually really scary just how much damage the us could do by simply forcing google to push an update with some malware . 
  there 's also the fact that japanese cars sell fine in europe as well . 
  if it really was protectionism that would n't be the case . 
  for anyone else , that 's true , but i do feel and experience pain for my self and assuming the obvious is true and the people around me are in fact real people , they would experience it in the same way . 
  machines however , by virtue of being mechanical constructs rather than biological creatures , have no inherent sense of pain . 
  in order for them to create it they would first need to comprehend it , and that 's where things fall apart . 
  to go back to a previous analogy , how would you explain smell to someone who ca n't smell . 
  you can show them the chemical components that make up the smell . 
  you can stimulate the brain in to giving them a reaction common to smelling a particular scent , but they still do n't know what it actually smells like . 
  it 's quite easy to make a machine that retracts when exposed to heat . 
  it 's unimaginably more difficult , if not impossible to actually experience the sensation of heat . 
  we proved that we can make electrical impulses behave in a way that allows them to simulate thought , but you ca n't make an electron or a bunch of electrons or lines of code or semi conductors or transistors actually experience anything . 
  yes , you could argue that on some level humans are the same , but that 's an assertion . 
  we simplify our own selves so that we may delude our selves that we understand our selves far better than we actually do . 
  at the same time we imagine a machine that thinks and acts like us , must posses the same traits as us . 
  we ascribe temperaments to things like cars so obviously we 'll do it for something that can actually talk to us , but the very simple truth is that machine intelligence is on a totally different axis . 
  it does n't work like human intelligence now , and there 's no reason to believe that it will or even could work that way . 
  react is the key word . 
  raction is easy , the feeling of pain however , that 's hard . 
  that 's just it . 
  we know it ca n't . 
  sure , it 's like pain centers in the brain being stimulated but with humans , the result of that is the sensation of pain , where as any machine , no matter how complex , could only have and output that says `` pain '' how do you teach a machine to feel pain ? 
  how would it learn to feel pain ? 
  how would you even begin to code how pain feels like . 
  the biologic part is easy , but it 's like trying to describe color to someone who 's blind , only it 's harder because it 's even more abstract and a machine is even less prone to grasping abstraction . 
  this then begs the larger question . 
  if a machine ca n't feel pain , it stands to reason that it ca n't really feel anything . 
  pain is a good example because it 's easy to grasp for any human . 
  you know when you 're in pain . 
  of all human feeling , this one is least prone to mislabeling . 
  leg on fire = pain , no real debate here , but how about revoltion ? 
  how would you teach a machine that something is revolting when most humans ca n't agree on what would count . 
  that is the fundamental limit of artificial intelligence . 
  it can think , it can understand , it can act and react , but in terms of actually feeling things , it 's more akin to a sociopath learning how to blend in by observation and imitation . 
  a simulacrum , a thing that was thought or that thought it self to pretend that it 's a person , to fool us in to believing it 's a person , but it ca n't ever be one . 
  here 's the thing though . 
  in humans , it is , because we can feel it . 
  a computer can acknowledge that value `` pain '' = true . 
  what exactly does it mean for for a mathematical equation ( and at the end of the day , that 's what an ai is ) to be in pain ? 
  the russian federation is right next to us . 
  does n't help them , would n't help us . 
  i agree . 
  i 'd rather be called the newly reformed holy roman empire of the german people and friends than be known as the use . 
  since you bring up ww2 . 
  look up the troop numbers , weapons and spending between nazi germany and the franco british alliance . 
  the allies had more of everything and we 're ready for war . 
  still lost in 6 weeks . 
  simulating a brain does create an interesting phylosophical conundrum . 
  on one hand , we would know full well that it was n't real . 
  the machine does n't have the hopes and needs of the simulated brain , it 's still just an elaborate set of calculations and if asked , the machine running it could easely `` show it 's work '' . 
  on the flip side , like you said , we too are ultimately biological machines that might one day be fully understand . 
  i would argue that this is n't a reason to consider robot rights though . 
  in law , there is a concert called a legal fiction and another one called a legal assumption . 
  a legal fiction is something that we know for a fact not to be true but pretend that it is as a matter of law , e.g. 
  that a child born after it 's fathers death was alive from the moment of conception for the purpose of inheritance , assuming the child is born alive . 
  a legal assumption is something we are n't really 100 % sure about but pretend to be as a matter of law . 
  free will is the age old example . 
  i bring this up because if we were to fully simulate a human brain in a way where we could n't destinguish it from a regular human , we would n't know that we created a unique , being . 
  quite the opposite . 
  since we know that it 's just a machine pretending , we would merely bring our own uniqueness in to question . 
  we would need to ask , are we too just pretending ? 
  do we also not meet our own criteria ? 
  that 's simply not practical . 
  it 's interesting to think about and discuss , but from a legal point of view there 's no reason to extend any human fiction or assumption on to a machine . 
  we assume that humans are special , that we have something more that elevates us . 
  we grant no such assumptions to a machine . 
  we know that we can simply save , load and copy a simulated brain . 
  we know it 's not special or unique and that turning it off and than back on does nothing in the way of harm , we simply ca n't consider it murder . 
  pain is essentially interesting . 
  we can simulate a mind experiencing it 's body burning in a fire , but there 's no body and no fire . 
  is a brain thinking about it 's body in pain in any way comparable to a body actually being in pain ? 
  we can simulate a body in order to better empathize , but again , it 's a machine thinking about a body in pain . 
  imitating a body in pain , pretending that there 's a body in pain , but the machine is fine , undamaged . 
  what is pain without the pain ? 
  there is . 
  we do n't know what it is , consequently we ca n't make it . 
  we 're building artificial intelligence . 
  that 's what we 're limited to . 
  not really . 
  a huge flaw in human thinking is anthropomorphization . 
  we take things that are n't human and give them human traits . 
  we did this to the forces of nature , ascribing storms to vengeful god 's and we do this to animals , seeing a dolphins mouth in a position resembling a smile and concluding that it means they 're happy even when they 're in pain .
