  if enough * interesting * information is removed , i could see activist groups in locations that do not extend this right ( china , us , india , etc ) simply running something like archive.org and refusing right-to-be-forgotten takedown requests . 
  sure , the eu could block access to these services from the eu , but that is n't really achieving what the eu wants . 
  further , i [ recall some serious turmoil in the uk over how political figures were using this to suppress undesirable information about themselves ] ( http://www.independent.co.uk/news/world/europe/law-firms-exploiting-eu-right-to-be-forgotten-ruling-to-help-individuals-remove-awkward-newspaper-10185164.html ) . 
  further , it 's not clear to me how effective this is in addressing the [ streisand effect ] ( https://en.wikipedia.org/wiki/streisand_effect ) . 
  i appreciate that going online creates an indelible , world-readable record , and that this is a real , practical change in privacy . 
  i think that to date , there are still some serious questions about how this is to be implemented . 
  that is , it seems to me , that some information is really in the public interest to be kept available * even if the individual in question would rather that not be the case * . 
   children , adolescents , disadvantaged and particularly vulnerable persons enjoy special protection in the digital world . 
  i think that adolescents are fine . 
  frankly , i think that the elderly are at greater risk than anyone else , based on historic scams . 
   everyone has a right to education that enables a self-determined life in the digital world . 
  would this better be put in a document relating to education , not digital issues ? 
  this seems to be kinda outside the scope . 
   digitization is an elementary educational challenge . 
  it is of central importance in the curricula of public education institutions . 
  i feel like this is a translation issue . 
  i 'm pretty sure that the authors do n't want to teach people to [ scan documents ] ( https://en.wikipedia.org/wiki/digitizing ) . 
  [ continued in child ], 
  [ continued from parent ]  ( 1 ) everyone has the right to not be the object of automated decisions of significant importance to the way of life . 
  insofar as automated procedures lead to impairments , a person is entitled to disclosure , review and decision . 
  the criteria for automated decisions are open . 
  i understand the general fear -- that somewhere a computer will decide that , say , someone 's credit is not trustworthy , they will appeal , the bank will say `` well , that 's what the computer says ... we do n't even know how that happens these days or what specifically set it off '' , and someone winds up caught in a kafkaesque nightmare . 
  i think that it is better to wait for actual issues to come up and let policy be created to address those than to try to legislate in advance here . 
  in particular , this might require european companies to disclose proprietary secrets in how they make decisions that would disadvantage them . 
  an insurer , for example , probably falls under this category , but the algorithms used to assess risk is their stock-in-trade , and to give them up may make it difficult for them to make money from and thus fund improvements in that decision making . 
  i would be more-sympathetic to the idea of establishing some sort of trusted appeals board that has the power to demand to see data used for and criteria used for the specifics of a decision . 
  that also means that people with technical knowledge in the particular area can be the ones examining the thing . 
  probably necessary to figure out some way to throttle the rate of appeals coming in , but that at least seems a lot more viable than simply mandating that the public have access to all criteria . 
   anonymity and transparency must be ensured , in particular , in the processing of mass data . 
  well ... anonymity always leaks to some degree . 
  there 's no real binary line between being anonymous and not . 
  for example , you can look at google trends and see where particular phrases are popular searches -- [ euromaidan ] ( https://www.google.com/trends/explore?q=euromaidan ) is important to ukraine , germany , and the united states , for example . 
  that 's * some * information leaking , but most people consider that acceptable , since the group of people is still very large . 
  on the other hand , disclosing an individual 's search history in entirety may be an issue . 
  furthermore , it may be possible to use multiple data sources that * individually * may not leak enough information to cross the line to deanonymize someone . 
  for example , if i run a forum and release its database , i might have real names and ip addresses and posting times . 
  combine that with another service that has ip addresses and posting times ( like wikipedia , which does this ) , and i can correlate the ip addresses and posting times and now know what john smith is reading and working on -- even if each individual thing did n't cross my red line for breaking anonymity . 
  if member countries implement this differently , it seems like it would result in a horrible mish-mash of useless legislation . 
  * if * anonymity guarantees are to be provided , it seems to me like ( a ) it should involve people specific with the technology involved and have rules specific to the country involved , ( b ) probably not be a timeless solution , but a `` solution for a decade '' , with new legislation required down the road , and ( c ) probably be best standardized across more member states , else information that may be released in one may be combined with that in another to deanonymize someone . 
  the transparency bit seems either like a polite nothingness or a requirement that would radically change how the digital world works . 
  for example , is google required to give up their advertisement-targeting algorithms if they operate in the eu ? 
  that is , after all , their stock-in-trade ...  ( 1 ) ethical-normative decisions can only be made by people . 
  i do n't honestly think that this is a risk that requires legislation . 
  that is , i do n't think that many people say `` i want and need a machine to set social norms for society without any human involvement '' . 
  further , people naturally will use computers * in the process * of determining norms . 
  if i do data-mining and determine that 30 percent of rapists below 40 years of age engage in [ recidivism ] ( https://en.wikipedia.org/wiki/recidivism ) , but that there is no recidivism among rapists above that age , perhaps i say `` it is acceptable for society to impose longer prison sentences on rapists until they reach the age of 40 for the protection of society '' . 
  i think that most would not want to interfere with this process , and to the extent that this is unclear , it might do that . 
   ( 2 ) the use and development of artificial intelligence in areas relevant to fundamental rights must be accompanied by society and regulated by the legislature . 
  either too vague or too restrictive to have effect . 
  suppose `` accompanied by society '' were removed here -- what actual effect would differ ? 
  i could understand this saying `` the european parliament shall have the power to regulate the use and development of artificial intelligence in areas relevant to fundamental rights '' . 
  that 's a meaningful classification of authority -- it takes power from member countries , and gives it to the ep . 
  i could understand this saying `` the legislature of each eu member shall establish a board of review which shall have the power to review and regulate the use of artificial intelligence in areas relevant to fundamental rights '' . 
  but as-is ... in all eu members , i suspect that the existing legislature already has the power to establish laws as regards ai . 
  so this seems like it does nothing in its current form . 
  i 'd add that in the us , this would n't make sense -- [ * federal regulations * ] ( https://en.wikipedia.org/wiki/code_of_federal_regulations ) are made by the executive branch , whereas [ the code of law ] ( https://en.wikipedia.org/wiki/united_states_code ) is made by the legislative branch , but i realize that this may be a translation issue or relate to the differences from a parliamentary system . 
   ( 3 ) a natural or legal person must always be responsible for the actions of self-learning machines and the resulting consequences . 
  neat that they thought of [ legal persons ] ( https://en.wikipedia.org/wiki/legal_personality ) . 
  that being said : ( 1 ) what happens if i set up a shell limited-liability-corporation or the european equivalent and make it responsible for half a million death-drones running around europe ? 
  maybe it has $ 100 in assets or so . 
  how much meaningful responsibility and ability to dissuade bad decisions or handle their consequences exists here ? 
  ( 2 ) i think that this is probably already realistically the case -- that is , i do n't think that any court would realistically rule that the operator of such a machine is not liable . 
  ( 3 ) it might be more-interesting to require that the person be made explicit , since otherwise , i see a mess of lawsuits over whether the creator of an ai or the operator is liable for what the ai does , or at least firm up criteria for determining that . 
  not even specific to ai -- i 'd like to know who is on the hook if , say , all self-driving cars freeze up on leap years , say . 
   in the case of infrastructures which are essential to the functioning of the company , state control and crises must be ensured . 
  how is that to be ensured ? 
  like , let 's say that i can reduce workers at a power plant by using ai . 
  where do i cross the line into inability to act ? 
  i guarantee that if all computer and telco systems went down today , power distribution in the us would be screwed up . 
  is ai to meet a higher bar than that ? 
  should maybe the criteria be that there be some form of `` stress tests '' that happen ? 
  perhaps that using ai disclose all their known risks and detail how they expect to permit ai control to be overriden in these cases ? 
  because as-is , it seems to be too vague to realistically do much . 
  if i 'm a company and you feed me a wildly-vague restriction , either i 'm going to just stay entirely away from the area as too unknown , or i 'm going to ignore the restriction and work it out in court if issues come up . 
  i 'm * not * going to be the one to spend a lot of money to have lawyers speculate what legal constraints probably exist on me . 
  [ continued in child ], 
  going off the english translation that i posted , comments :  the dignity of man is inviolable even in the digital age . 
  as far as i know , this is redundant based on existing eu material . 
   it must be the aim and purpose of all technical development and limit their use . 
  i 'm still a little fuzzy on the precise extent of what `` the dignity of man '' is , but that seems over-restrictive . 
   new dangers of human dignity emerge in the digital age , in particular by means of big data , artificial intelligence , prediction and control of human behavior , mass monitoring , the use of algorithms , robotics and man-machine fusion as well as power concentration in private companies . 
  i 'd suggest that documents like this should seek to be timeless insofar as is possible . 
  i 'd eliminate specific technologies where possible . 
  i 'm personally not enthusiastic about the criticism of companies -- as far as i know , this is not the norm for existing eu documents . 
   the rights under this charter apply to governmental bodies and private individuals . 
  i do n't understand what this means . 
  does this means that the rights do not apply to ngos like greenpeace or to companies ? 
  do they apply to foreign government bodies ? 
  what is the jurisdiction here -- do these claim to apply to , say , german companies dealing with private chinese citizens ? 
  chinese companies dealing with german citizens ? 
   everyone has a right to free information and communication . 
  i do n't understand what this means . 
  may be the english translation , but is this * libre * or * gratis * ? 
  is this a [ positive right ] ( https://en.wikipedia.org/wiki/negative_and_positive_rights ) guaranteeing government-funded internet service ( and access to any * future * information services , without fee , like academic publications ? ), 
  how does this interact with existing restrictions on , say , hate speech or copyright ? 
   it includes the right to non-knowledge . 
  i do n't know what this means . 
  how can i make the call to not know about something if i do n't know what it is ? 
  does this mean that , for example , it is guaranteed that a government permit a four-year-old me to sign away my right to access to knowledge on various subjects for a candy ? 
   everyone has the right to an equal participation in the digital sphere .
