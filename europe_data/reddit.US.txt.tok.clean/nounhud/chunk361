    ( 2 ) everyone has the right to determine his own data . 
  personal data may be collected and processed only in good faith and for specified purposes if this is necessary for the respective use relationship and has been given prior consent or on a legal basis . 
  consent must be express and informed . 
  usage conditions must be fair and transparent . 
    ( 3 ) compliance with these rights is monitored by an independent body . 
    ( 4 ) providers of services or products may collect and process only those data which are necessary for the purpose of the use . 
  the principles of privacy by design and privacy by default must be adhered to . 
    ** article 12 **   informational self-determination   ( 1 ) the integrity , confidentiality and integrity of information technology systems shall be ensured . 
    ( 2 ) everyone has the right to encrypt their data . 
    ** article 13 **   data security   ( 1 ) everyone has a right to the security of information technology systems and the data processed by them . 
  the highest possible protection is to be ensured . 
    ( 2 ) identity theft and identity falsification must be combated . 
    ** article 14 **   elections   the right to vote and vote must not be restricted to access to digital media . 
    ** article 15 **   free access   ( 1 ) everyone has the right to free , equal and anonymous access to communications services without having to renounce basic rights . 
  the internet is part of the basic supply . 
    ( 2 ) everyone has the right to a non-personalized use of digital offers . 
    ** article 16 **   network neutrality   network neutrality is to be ensured . 
  this also applies to services that provide access to the digital sphere . 
    ** article 17 **   plurality and competition   in the digital world , pluralism and cultural diversity must be ensured . 
  open standards must be encouraged . 
  market abuse is to be prevented effectively . 
    ** article 18 **   right to be forgotten   everyone has the right to a digital new beginning . 
  this right finds its limits in the legitimate information interests of the public . 
    ** article 19 **   particularly vulnerable persons   children , adolescents , disadvantaged and particularly vulnerable persons enjoy special protection in the digital world . 
  their participation in the digital world is to be encouraged . 
    ** article 20 **   education   ( 1 ) everyone has a right to education that enables a self-determined life in the digital world . 
    ( 2 ) digitization is an elementary educational challenge . 
  it is of central importance in the curricula of public education institutions . 
    ** article 21 **   job   ( 1 ) work remains an important foundation of life support and self-realization . 
    ( 2 ) effective employment protection must be ensured in the digital age . 
    ( 3 ) digital structural change is to be shaped according to social principles . 
    ** article 22 **   immaterial goods   rights holders are entitled to a fair share of the proceeds from the digital use of their intangible assets . 
  these rights must be balanced with non-commercial use interests . 
    ** article 23 **   final provisions   ( 1 ) the interpretation of the rights contained in this charter is ultimately the responsibility of the european court of justice . 
    ( 2 ) the exercise and restriction of the rights and principles of this charter shall be in accordance with article 52 ecc . 
    ( 3 ) rights and obligations under this charter apply to all companies active in the eu . 
  the setting-up of a court outside the eu is not permitted . 
  i asked about him before , and people responding to the question from france repeatedly-criticized him for being from a left-wing party with a left-wing platform , yet promoting liberal economic reforms . 
  while i think that those policies are to france 's benefit , they said that people felt betrayed . 
  [ continued from parent ]  ( 1 ) everyone has the right to not be the object of automated decisions of significant importance to the way of life . 
  insofar as automated procedures lead to impairments , a person is entitled to disclosure , review and decision . 
  the criteria for automated decisions are open . 
  i understand the general fear -- that somewhere a computer will decide that , say , someone 's credit is not trustworthy , they will appeal , the bank will say `` well , that 's what the computer says ... we do n't even know how that happens these days or what specifically set it off '' , and someone winds up caught in a kafkaesque nightmare . 
  i think that it is better to wait for actual issues to come up and let policy be created to address those than to try to legislate in advance here . 
  in particular , this might require european companies to disclose proprietary secrets in how they make decisions that would disadvantage them . 
  an insurer , for example , probably falls under this category , but the algorithms used to assess risk is their stock-in-trade , and to give them up may make it difficult for them to make money from and thus fund improvements in that decision making . 
  i would be more-sympathetic to the idea of establishing some sort of trusted appeals board that has the power to demand access access to the criteria and review the specifics of a decision . 
  probably necessary to figure out some way to throttle the rate of appeals coming in , but that at least seems a lot more viable than simply mandating that the public have access to all criteria . 
  [ okay , apparently this article was removed , so i guess nobody will read further comments :-( ], 
  going off the english translation that i posted , comments :  the dignity of man is inviolable even in the digital age . 
  as far as i know , this is redundant based on existing eu material . 
   it must be the aim and purpose of all technical development and limit their use . 
  i 'm still a little fuzzy on the precise extent of what `` the dignity of man '' is , but that seems over-restrictive . 
   new dangers of human dignity emerge in the digital age , in particular by means of big data , artificial intelligence , prediction and control of human behavior , mass monitoring , the use of algorithms , robotics and man-machine fusion as well as power concentration in private companies . 
  i 'd suggest that documents like this should seek to be timeless insofar as is possible . 
  i 'd eliminate specific technologies where possible . 
  i 'm personally not enthusiastic about the criticism of companies -- as far as i know , this is not the norm for existing eu documents . 
   the rights under this charter apply to governmental bodies and private individuals . 
  i do n't understand what this means . 
  does this means that the rights do not apply to ngos like greenpeace or to companies ? 
  do they apply to foreign government bodies ? 
  what is the jurisdiction here -- do these claim to apply to , say , german companies dealing with private chinese citizens ? 
  chinese companies dealing with german citizens ? 
   everyone has a right to free information and communication . 
  i do n't understand what this means . 
  may be the english translation , but is this * libre * or * gratis * ? 
  is this a [ positive right ] ( https://en.wikipedia.org/wiki/negative_and_positive_rights ) guaranteeing government-funded internet service ( and access to any * future * information services , without fee , like academic publications ? ), 
  how does this interact with existing restrictions on , say , hate speech or copyright ? 
   it includes the right to non-knowledge . 
  i do n't know what this means . 
  how can i make the call to not know about something if i do n't know what it is ? 
  does this mean that , for example , it is guaranteed that a government permit a four-year-old me to sign away my right to access to knowledge on various subjects for a candy ? 
   everyone has the right to an equal participation in the digital sphere . 
  is this a positive right , where government must subsidize to smooth out economic differences ? 
  if someone lives in french guiana , are they required to have the same throughput available for the same price as someone living in berlin ? 
  how does this interact with existing hate speech regulation ? 
   the use of automated procedures must not lead to the exclusion of people from access to goods , services or participation in social life . 
  this applies in particular to health , protection from elementary life risks , right to work , right to housing , right to freedom of movement , and to the judiciary and the police . 
  i assume that this is aimed at reassurance for people whose jobs are threatened by automation . 
  it might be desirable to * control * that rate , but i do n't think that people should be guaranteed that the state or companies prevent jobs from being automated at all , or it may seriously hamper europe 's ability to economically-compete . 
   ( 1 ) in the digital age , internal and external security is threatened in a new way . 
  in the exercise of the responsibility for the protection of the state , strict legal limits must be observed . 
  seems redundant -- this is just saying `` laws must be followed '' , yes ? 
  surely that would already have been the case . 
   ( 2 ) security authorities shall not access private data . 
  exceptions are only permissible on the legal basis for the protection of particularly important legal goods . 
  i 've never liked loopholes like this that might obsolete the guarantee entirely , but from what i 've read of constitutions and similar documents in europe , this kind of `` soft '' guarantee is a lot more common over there , so this may just be a difference in approach . 
   ( 3 ) massless monitoring is not carried out . 
  the translation is bad here . 
  i do n't know whether this is `` baseless '' monitoring ( as in , monitoring without a warrant ) or `` electronic '' monitoring . 
  the former * might * be viable , but seems excessively-broad -- for example , that would seem to ban , say , traffic cameras . 
  the latter seems too broad . 
   ( 4 ) weapon systems may not be fully automated . 
  i would be more-specific . 
  for example , does an `` on/off '' switch suffice ? 
  does someone have to take action at every point in time ? 
  do the rules change when at war ? 
  what about defensive systems ? 
  i can understand establishing certain `` lines '' that everyone can agree on , like standardizing the degree to which long-range missile systems require human authorization . 
  i am a lot less-sanguine about placing restrictions on point-defense systems like [ phalanx ciws ] ( https://en.wikipedia.org/wiki/phalanx_ciws ) , [ tunguska ] ( https://en.wikipedia.org/wiki/2k22_tunguska ) , [ ds30m ] ( https://en.wikipedia.org/wiki/30mm_ds30m_mark_2_automated_small_calibre_gun ) , [ meroka ciws ] ( https://en.wikipedia.org/wiki/meroka_ciws ) , [ goalkeeper ciws ] ( https://en.wikipedia.org/wiki/goalkeeper_ciws ) , [ gdm-008 ] ( https://en.wikipedia.org/wiki/rheinmetall_oerlikon_millennium_gun ) , and similar .
