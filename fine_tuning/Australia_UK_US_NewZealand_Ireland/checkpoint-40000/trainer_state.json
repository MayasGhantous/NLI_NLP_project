{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.114220777504691,
  "eval_steps": 500,
  "global_step": 40000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026427759718808636,
      "grad_norm": 3.168142557144165,
      "learning_rate": 4.955952569727083e-05,
      "loss": 3.3609,
      "step": 500
    },
    {
      "epoch": 0.05285551943761727,
      "grad_norm": 2.28806209564209,
      "learning_rate": 4.9119051394541646e-05,
      "loss": 3.2477,
      "step": 1000
    },
    {
      "epoch": 0.07928327915642591,
      "grad_norm": 2.053124189376831,
      "learning_rate": 4.8678577091812465e-05,
      "loss": 3.2037,
      "step": 1500
    },
    {
      "epoch": 0.10571103887523454,
      "grad_norm": 1.7595739364624023,
      "learning_rate": 4.823810278908329e-05,
      "loss": 3.1833,
      "step": 2000
    },
    {
      "epoch": 0.13213879859404318,
      "grad_norm": 1.6984285116195679,
      "learning_rate": 4.779762848635411e-05,
      "loss": 3.1724,
      "step": 2500
    },
    {
      "epoch": 0.15856655831285182,
      "grad_norm": 1.6161808967590332,
      "learning_rate": 4.735715418362493e-05,
      "loss": 3.1511,
      "step": 3000
    },
    {
      "epoch": 0.18499431803166044,
      "grad_norm": 1.5129437446594238,
      "learning_rate": 4.691667988089575e-05,
      "loss": 3.1428,
      "step": 3500
    },
    {
      "epoch": 0.2114220777504691,
      "grad_norm": 1.4667860269546509,
      "learning_rate": 4.647620557816657e-05,
      "loss": 3.1357,
      "step": 4000
    },
    {
      "epoch": 0.23784983746927774,
      "grad_norm": 1.378353476524353,
      "learning_rate": 4.6035731275437396e-05,
      "loss": 3.1281,
      "step": 4500
    },
    {
      "epoch": 0.26427759718808636,
      "grad_norm": 1.3927406072616577,
      "learning_rate": 4.5595256972708215e-05,
      "loss": 3.1184,
      "step": 5000
    },
    {
      "epoch": 0.29070535690689503,
      "grad_norm": 1.2780348062515259,
      "learning_rate": 4.5154782669979033e-05,
      "loss": 3.1081,
      "step": 5500
    },
    {
      "epoch": 0.31713311662570365,
      "grad_norm": 1.307328701019287,
      "learning_rate": 4.471430836724986e-05,
      "loss": 3.108,
      "step": 6000
    },
    {
      "epoch": 0.34356087634451227,
      "grad_norm": 1.2803421020507812,
      "learning_rate": 4.427383406452068e-05,
      "loss": 3.099,
      "step": 6500
    },
    {
      "epoch": 0.3699886360633209,
      "grad_norm": 1.1908282041549683,
      "learning_rate": 4.3833359761791496e-05,
      "loss": 3.1019,
      "step": 7000
    },
    {
      "epoch": 0.39641639578212956,
      "grad_norm": 1.207866907119751,
      "learning_rate": 4.339288545906232e-05,
      "loss": 3.0948,
      "step": 7500
    },
    {
      "epoch": 0.4228441555009382,
      "grad_norm": 1.174971580505371,
      "learning_rate": 4.295241115633314e-05,
      "loss": 3.0932,
      "step": 8000
    },
    {
      "epoch": 0.4492719152197468,
      "grad_norm": 1.248582363128662,
      "learning_rate": 4.2511936853603965e-05,
      "loss": 3.0929,
      "step": 8500
    },
    {
      "epoch": 0.4756996749385555,
      "grad_norm": 1.244201898574829,
      "learning_rate": 4.2071462550874784e-05,
      "loss": 3.0828,
      "step": 9000
    },
    {
      "epoch": 0.5021274346573641,
      "grad_norm": 1.1029824018478394,
      "learning_rate": 4.16309882481456e-05,
      "loss": 3.0863,
      "step": 9500
    },
    {
      "epoch": 0.5285551943761727,
      "grad_norm": 1.193241000175476,
      "learning_rate": 4.119051394541643e-05,
      "loss": 3.0766,
      "step": 10000
    },
    {
      "epoch": 0.5549829540949813,
      "grad_norm": 1.1748771667480469,
      "learning_rate": 4.0750039642687246e-05,
      "loss": 3.0729,
      "step": 10500
    },
    {
      "epoch": 0.5814107138137901,
      "grad_norm": 1.0678536891937256,
      "learning_rate": 4.0309565339958065e-05,
      "loss": 3.0761,
      "step": 11000
    },
    {
      "epoch": 0.6078384735325987,
      "grad_norm": 1.1032540798187256,
      "learning_rate": 3.986909103722889e-05,
      "loss": 3.0716,
      "step": 11500
    },
    {
      "epoch": 0.6342662332514073,
      "grad_norm": 1.1376395225524902,
      "learning_rate": 3.9428616734499715e-05,
      "loss": 3.0655,
      "step": 12000
    },
    {
      "epoch": 0.6606939929702159,
      "grad_norm": 1.0578969717025757,
      "learning_rate": 3.898814243177053e-05,
      "loss": 3.0662,
      "step": 12500
    },
    {
      "epoch": 0.6871217526890245,
      "grad_norm": 1.0986108779907227,
      "learning_rate": 3.854766812904135e-05,
      "loss": 3.0602,
      "step": 13000
    },
    {
      "epoch": 0.7135495124078332,
      "grad_norm": 1.0447267293930054,
      "learning_rate": 3.810719382631218e-05,
      "loss": 3.0612,
      "step": 13500
    },
    {
      "epoch": 0.7399772721266418,
      "grad_norm": 1.1033638715744019,
      "learning_rate": 3.7666719523582996e-05,
      "loss": 3.0646,
      "step": 14000
    },
    {
      "epoch": 0.7664050318454505,
      "grad_norm": 1.066247820854187,
      "learning_rate": 3.7226245220853815e-05,
      "loss": 3.0555,
      "step": 14500
    },
    {
      "epoch": 0.7928327915642591,
      "grad_norm": 1.1047388315200806,
      "learning_rate": 3.678577091812464e-05,
      "loss": 3.0528,
      "step": 15000
    },
    {
      "epoch": 0.8192605512830677,
      "grad_norm": 1.087972640991211,
      "learning_rate": 3.634529661539546e-05,
      "loss": 3.0547,
      "step": 15500
    },
    {
      "epoch": 0.8456883110018764,
      "grad_norm": 1.070616364479065,
      "learning_rate": 3.5904822312666284e-05,
      "loss": 3.0493,
      "step": 16000
    },
    {
      "epoch": 0.872116070720685,
      "grad_norm": 1.0031952857971191,
      "learning_rate": 3.54643480099371e-05,
      "loss": 3.0497,
      "step": 16500
    },
    {
      "epoch": 0.8985438304394936,
      "grad_norm": 1.0821107625961304,
      "learning_rate": 3.502387370720792e-05,
      "loss": 3.0517,
      "step": 17000
    },
    {
      "epoch": 0.9249715901583023,
      "grad_norm": 1.0353569984436035,
      "learning_rate": 3.4583399404478746e-05,
      "loss": 3.0488,
      "step": 17500
    },
    {
      "epoch": 0.951399349877111,
      "grad_norm": 1.006638526916504,
      "learning_rate": 3.4142925101749565e-05,
      "loss": 3.0413,
      "step": 18000
    },
    {
      "epoch": 0.9778271095959196,
      "grad_norm": 1.1419892311096191,
      "learning_rate": 3.3702450799020383e-05,
      "loss": 3.0388,
      "step": 18500
    },
    {
      "epoch": 0.9999735722402812,
      "eval_loss": 2.978839159011841,
      "eval_runtime": 215.6275,
      "eval_samples_per_second": 175.817,
      "eval_steps_per_second": 21.978,
      "step": 18919
    },
    {
      "epoch": 1.0042548693147282,
      "grad_norm": 1.0806877613067627,
      "learning_rate": 3.326197649629121e-05,
      "loss": 3.0342,
      "step": 19000
    },
    {
      "epoch": 1.030682629033537,
      "grad_norm": 1.0450893640518188,
      "learning_rate": 3.2821502193562034e-05,
      "loss": 2.9856,
      "step": 19500
    },
    {
      "epoch": 1.0571103887523454,
      "grad_norm": 1.0366604328155518,
      "learning_rate": 3.2381027890832846e-05,
      "loss": 2.9832,
      "step": 20000
    },
    {
      "epoch": 1.0835381484711541,
      "grad_norm": 1.0664509534835815,
      "learning_rate": 3.194055358810367e-05,
      "loss": 2.9889,
      "step": 20500
    },
    {
      "epoch": 1.1099659081899627,
      "grad_norm": 1.0828659534454346,
      "learning_rate": 3.1500079285374496e-05,
      "loss": 2.9858,
      "step": 21000
    },
    {
      "epoch": 1.1363936679087714,
      "grad_norm": 1.0486907958984375,
      "learning_rate": 3.1059604982645315e-05,
      "loss": 2.9857,
      "step": 21500
    },
    {
      "epoch": 1.1628214276275801,
      "grad_norm": 1.0747684240341187,
      "learning_rate": 3.0619130679916134e-05,
      "loss": 2.9845,
      "step": 22000
    },
    {
      "epoch": 1.1892491873463886,
      "grad_norm": 1.067668080329895,
      "learning_rate": 3.017865637718696e-05,
      "loss": 2.9874,
      "step": 22500
    },
    {
      "epoch": 1.2156769470651974,
      "grad_norm": 1.0374186038970947,
      "learning_rate": 2.9738182074457777e-05,
      "loss": 2.9829,
      "step": 23000
    },
    {
      "epoch": 1.2421047067840059,
      "grad_norm": 1.0583922863006592,
      "learning_rate": 2.92977077717286e-05,
      "loss": 2.9909,
      "step": 23500
    },
    {
      "epoch": 1.2685324665028146,
      "grad_norm": 1.0066865682601929,
      "learning_rate": 2.8857233468999418e-05,
      "loss": 2.9844,
      "step": 24000
    },
    {
      "epoch": 1.2949602262216233,
      "grad_norm": 1.0749351978302002,
      "learning_rate": 2.841675916627024e-05,
      "loss": 2.9901,
      "step": 24500
    },
    {
      "epoch": 1.3213879859404318,
      "grad_norm": 1.034119963645935,
      "learning_rate": 2.7976284863541065e-05,
      "loss": 2.9898,
      "step": 25000
    },
    {
      "epoch": 1.3478157456592403,
      "grad_norm": 1.048239827156067,
      "learning_rate": 2.753581056081188e-05,
      "loss": 2.9799,
      "step": 25500
    },
    {
      "epoch": 1.374243505378049,
      "grad_norm": 1.0348753929138184,
      "learning_rate": 2.7095336258082706e-05,
      "loss": 2.9852,
      "step": 26000
    },
    {
      "epoch": 1.4006712650968578,
      "grad_norm": 1.0172802209854126,
      "learning_rate": 2.6654861955353528e-05,
      "loss": 2.9817,
      "step": 26500
    },
    {
      "epoch": 1.4270990248156663,
      "grad_norm": 1.0271618366241455,
      "learning_rate": 2.6214387652624346e-05,
      "loss": 2.9959,
      "step": 27000
    },
    {
      "epoch": 1.453526784534475,
      "grad_norm": 1.0668156147003174,
      "learning_rate": 2.5773913349895168e-05,
      "loss": 2.9877,
      "step": 27500
    },
    {
      "epoch": 1.4799545442532835,
      "grad_norm": 1.0544054508209229,
      "learning_rate": 2.533343904716599e-05,
      "loss": 2.981,
      "step": 28000
    },
    {
      "epoch": 1.5063823039720923,
      "grad_norm": 1.0089750289916992,
      "learning_rate": 2.4892964744436812e-05,
      "loss": 2.9931,
      "step": 28500
    },
    {
      "epoch": 1.532810063690901,
      "grad_norm": 0.9933094382286072,
      "learning_rate": 2.445249044170763e-05,
      "loss": 2.9862,
      "step": 29000
    },
    {
      "epoch": 1.5592378234097095,
      "grad_norm": 1.012624979019165,
      "learning_rate": 2.4012016138978452e-05,
      "loss": 2.9797,
      "step": 29500
    },
    {
      "epoch": 1.5856655831285182,
      "grad_norm": 1.0232141017913818,
      "learning_rate": 2.3571541836249274e-05,
      "loss": 2.9781,
      "step": 30000
    },
    {
      "epoch": 1.6120933428473267,
      "grad_norm": 1.06564462184906,
      "learning_rate": 2.3131067533520096e-05,
      "loss": 2.978,
      "step": 30500
    },
    {
      "epoch": 1.6385211025661355,
      "grad_norm": 1.115347146987915,
      "learning_rate": 2.2690593230790915e-05,
      "loss": 2.9813,
      "step": 31000
    },
    {
      "epoch": 1.6649488622849442,
      "grad_norm": 1.0281472206115723,
      "learning_rate": 2.225011892806174e-05,
      "loss": 2.9775,
      "step": 31500
    },
    {
      "epoch": 1.6913766220037527,
      "grad_norm": 1.0389137268066406,
      "learning_rate": 2.180964462533256e-05,
      "loss": 2.9808,
      "step": 32000
    },
    {
      "epoch": 1.7178043817225612,
      "grad_norm": 1.0340583324432373,
      "learning_rate": 2.136917032260338e-05,
      "loss": 2.9801,
      "step": 32500
    },
    {
      "epoch": 1.74423214144137,
      "grad_norm": 1.001137137413025,
      "learning_rate": 2.0928696019874202e-05,
      "loss": 2.972,
      "step": 33000
    },
    {
      "epoch": 1.7706599011601787,
      "grad_norm": 1.094191551208496,
      "learning_rate": 2.0488221717145024e-05,
      "loss": 2.9765,
      "step": 33500
    },
    {
      "epoch": 1.7970876608789874,
      "grad_norm": 1.0015100240707397,
      "learning_rate": 2.0047747414415843e-05,
      "loss": 2.9775,
      "step": 34000
    },
    {
      "epoch": 1.823515420597796,
      "grad_norm": 1.0381426811218262,
      "learning_rate": 1.9607273111686665e-05,
      "loss": 2.9765,
      "step": 34500
    },
    {
      "epoch": 1.8499431803166044,
      "grad_norm": 1.0754042863845825,
      "learning_rate": 1.9166798808957487e-05,
      "loss": 2.9691,
      "step": 35000
    },
    {
      "epoch": 1.8763709400354132,
      "grad_norm": 1.070554256439209,
      "learning_rate": 1.872632450622831e-05,
      "loss": 2.9709,
      "step": 35500
    },
    {
      "epoch": 1.902798699754222,
      "grad_norm": 1.0708706378936768,
      "learning_rate": 1.8285850203499127e-05,
      "loss": 2.966,
      "step": 36000
    },
    {
      "epoch": 1.9292264594730306,
      "grad_norm": 0.9746537804603577,
      "learning_rate": 1.784537590076995e-05,
      "loss": 2.9723,
      "step": 36500
    },
    {
      "epoch": 1.9556542191918391,
      "grad_norm": 1.0385173559188843,
      "learning_rate": 1.740490159804077e-05,
      "loss": 2.9699,
      "step": 37000
    },
    {
      "epoch": 1.9820819789106476,
      "grad_norm": 1.0569896697998047,
      "learning_rate": 1.696442729531159e-05,
      "loss": 2.9743,
      "step": 37500
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.949985980987549,
      "eval_runtime": 215.2608,
      "eval_samples_per_second": 176.117,
      "eval_steps_per_second": 22.015,
      "step": 37839
    },
    {
      "epoch": 2.0085097386294564,
      "grad_norm": 1.0215567350387573,
      "learning_rate": 1.6523952992582415e-05,
      "loss": 2.9598,
      "step": 38000
    },
    {
      "epoch": 2.034937498348265,
      "grad_norm": 1.177704930305481,
      "learning_rate": 1.6083478689853234e-05,
      "loss": 2.9342,
      "step": 38500
    },
    {
      "epoch": 2.061365258067074,
      "grad_norm": 1.0790127515792847,
      "learning_rate": 1.5643004387124056e-05,
      "loss": 2.9375,
      "step": 39000
    },
    {
      "epoch": 2.087793017785882,
      "grad_norm": 1.0450439453125,
      "learning_rate": 1.5202530084394877e-05,
      "loss": 2.9341,
      "step": 39500
    },
    {
      "epoch": 2.114220777504691,
      "grad_norm": 1.1174496412277222,
      "learning_rate": 1.4762055781665698e-05,
      "loss": 2.9344,
      "step": 40000
    }
  ],
  "logging_steps": 500,
  "max_steps": 56757,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.1806202535936e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
