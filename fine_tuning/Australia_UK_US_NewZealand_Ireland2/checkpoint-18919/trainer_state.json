{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999735722402812,
  "eval_steps": 500,
  "global_step": 18919,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026427759718808636,
      "grad_norm": 1.0367863178253174,
      "learning_rate": 4.8678577091812465e-05,
      "loss": 2.9434,
      "step": 500
    },
    {
      "epoch": 0.05285551943761727,
      "grad_norm": 1.0153659582138062,
      "learning_rate": 4.735715418362493e-05,
      "loss": 2.9493,
      "step": 1000
    },
    {
      "epoch": 0.07928327915642591,
      "grad_norm": 1.0227744579315186,
      "learning_rate": 4.6035731275437396e-05,
      "loss": 2.9441,
      "step": 1500
    },
    {
      "epoch": 0.10571103887523454,
      "grad_norm": 1.0233601331710815,
      "learning_rate": 4.471430836724986e-05,
      "loss": 2.9459,
      "step": 2000
    },
    {
      "epoch": 0.13213879859404318,
      "grad_norm": 1.0224369764328003,
      "learning_rate": 4.339288545906232e-05,
      "loss": 2.9508,
      "step": 2500
    },
    {
      "epoch": 0.15856655831285182,
      "grad_norm": 1.0642969608306885,
      "learning_rate": 4.2071462550874784e-05,
      "loss": 2.9429,
      "step": 3000
    },
    {
      "epoch": 0.18499431803166044,
      "grad_norm": 1.0020729303359985,
      "learning_rate": 4.0750039642687246e-05,
      "loss": 2.9434,
      "step": 3500
    },
    {
      "epoch": 0.2114220777504691,
      "grad_norm": 1.0185868740081787,
      "learning_rate": 3.9428616734499715e-05,
      "loss": 2.9456,
      "step": 4000
    },
    {
      "epoch": 0.23784983746927774,
      "grad_norm": 1.000794768333435,
      "learning_rate": 3.810719382631218e-05,
      "loss": 2.9471,
      "step": 4500
    },
    {
      "epoch": 0.26427759718808636,
      "grad_norm": 0.9763725399971008,
      "learning_rate": 3.678577091812464e-05,
      "loss": 2.9427,
      "step": 5000
    },
    {
      "epoch": 0.29070535690689503,
      "grad_norm": 0.9951784610748291,
      "learning_rate": 3.54643480099371e-05,
      "loss": 2.9385,
      "step": 5500
    },
    {
      "epoch": 0.31713311662570365,
      "grad_norm": 0.9929009079933167,
      "learning_rate": 3.4142925101749565e-05,
      "loss": 2.9418,
      "step": 6000
    },
    {
      "epoch": 0.34356087634451227,
      "grad_norm": 0.9952725172042847,
      "learning_rate": 3.2821502193562034e-05,
      "loss": 2.938,
      "step": 6500
    },
    {
      "epoch": 0.3699886360633209,
      "grad_norm": 0.9715567827224731,
      "learning_rate": 3.1500079285374496e-05,
      "loss": 2.9453,
      "step": 7000
    },
    {
      "epoch": 0.39641639578212956,
      "grad_norm": 0.9976015686988831,
      "learning_rate": 3.017865637718696e-05,
      "loss": 2.9397,
      "step": 7500
    },
    {
      "epoch": 0.4228441555009382,
      "grad_norm": 0.9984696507453918,
      "learning_rate": 2.8857233468999418e-05,
      "loss": 2.9435,
      "step": 8000
    },
    {
      "epoch": 0.4492719152197468,
      "grad_norm": 1.1007505655288696,
      "learning_rate": 2.753581056081188e-05,
      "loss": 2.9449,
      "step": 8500
    },
    {
      "epoch": 0.4756996749385555,
      "grad_norm": 1.0358928442001343,
      "learning_rate": 2.6214387652624346e-05,
      "loss": 2.9388,
      "step": 9000
    },
    {
      "epoch": 0.5021274346573641,
      "grad_norm": 0.9611765742301941,
      "learning_rate": 2.4892964744436812e-05,
      "loss": 2.9454,
      "step": 9500
    },
    {
      "epoch": 0.5285551943761727,
      "grad_norm": 1.0358116626739502,
      "learning_rate": 2.3571541836249274e-05,
      "loss": 2.9375,
      "step": 10000
    },
    {
      "epoch": 0.5549829540949813,
      "grad_norm": 1.0200451612472534,
      "learning_rate": 2.225011892806174e-05,
      "loss": 2.9359,
      "step": 10500
    },
    {
      "epoch": 0.5814107138137901,
      "grad_norm": 0.9740340709686279,
      "learning_rate": 2.0928696019874202e-05,
      "loss": 2.9411,
      "step": 11000
    },
    {
      "epoch": 0.6078384735325987,
      "grad_norm": 0.9652355313301086,
      "learning_rate": 1.9607273111686665e-05,
      "loss": 2.9385,
      "step": 11500
    },
    {
      "epoch": 0.6342662332514073,
      "grad_norm": 1.0263807773590088,
      "learning_rate": 1.8285850203499127e-05,
      "loss": 2.9345,
      "step": 12000
    },
    {
      "epoch": 0.6606939929702159,
      "grad_norm": 0.9939520359039307,
      "learning_rate": 1.696442729531159e-05,
      "loss": 2.9362,
      "step": 12500
    },
    {
      "epoch": 0.6871217526890245,
      "grad_norm": 0.9829235076904297,
      "learning_rate": 1.5643004387124056e-05,
      "loss": 2.9325,
      "step": 13000
    },
    {
      "epoch": 0.7135495124078332,
      "grad_norm": 0.9511601328849792,
      "learning_rate": 1.432158147893652e-05,
      "loss": 2.9347,
      "step": 13500
    },
    {
      "epoch": 0.7399772721266418,
      "grad_norm": 0.9853307604789734,
      "learning_rate": 1.3000158570748982e-05,
      "loss": 2.9408,
      "step": 14000
    },
    {
      "epoch": 0.7664050318454505,
      "grad_norm": 1.0191421508789062,
      "learning_rate": 1.1678735662561446e-05,
      "loss": 2.9319,
      "step": 14500
    },
    {
      "epoch": 0.7928327915642591,
      "grad_norm": 0.9827412366867065,
      "learning_rate": 1.035731275437391e-05,
      "loss": 2.9314,
      "step": 15000
    },
    {
      "epoch": 0.8192605512830677,
      "grad_norm": 1.0016067028045654,
      "learning_rate": 9.035889846186374e-06,
      "loss": 2.9352,
      "step": 15500
    },
    {
      "epoch": 0.8456883110018764,
      "grad_norm": 0.9716238379478455,
      "learning_rate": 7.714466937998838e-06,
      "loss": 2.9308,
      "step": 16000
    },
    {
      "epoch": 0.872116070720685,
      "grad_norm": 0.9871212840080261,
      "learning_rate": 6.393044029811302e-06,
      "loss": 2.932,
      "step": 16500
    },
    {
      "epoch": 0.8985438304394936,
      "grad_norm": 1.000593662261963,
      "learning_rate": 5.071621121623765e-06,
      "loss": 2.9353,
      "step": 17000
    },
    {
      "epoch": 0.9249715901583023,
      "grad_norm": 1.0112848281860352,
      "learning_rate": 3.750198213436228e-06,
      "loss": 2.9331,
      "step": 17500
    },
    {
      "epoch": 0.951399349877111,
      "grad_norm": 0.9633746147155762,
      "learning_rate": 2.428775305248692e-06,
      "loss": 2.9284,
      "step": 18000
    },
    {
      "epoch": 0.9778271095959196,
      "grad_norm": 1.059537649154663,
      "learning_rate": 1.1073523970611556e-06,
      "loss": 2.9248,
      "step": 18500
    }
  ],
  "logging_steps": 500,
  "max_steps": 18919,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9773535813632e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
