  perhaps similarly humans are consciousness-complete and the further differences are iq quantity only ; just better data mining/patten recognition pumps for our knowledge bases and the like . 
  mere extreme iq need n't have such magical consequences or even in fact be beyond our understanding as the notion of singularity seems to imply . 
  it may not even be the bottleneck to progress now . . 
  damn , rambling again :p, 
  well izvan blamaze s perkovicem ... 
   `` there was moderate-quality evidence to support the use of cannabinoids for the treatment of chronic pain and spasticity . 
  there was low-quality evidence suggesting that cannabinoids were associated with improvements in nausea and vomiting due to chemotherapy , weight gain in hiv infection , sleep disorders , and tourette syndrome . '', 
  sounds about right . 
  though i thought it had a fair bit of support for increasing appetite ? 
  or maybe that 's what they mean with `` weight gain in hiv infection '' . 
  whatever the exact scenarios of correct use , seems it could indeed have some legitimate symptomatic use but it certainly does n't cure anything . 
  though chronic pain management seems a major matter . 
  and sure , any of those either are already isolated and licensed as single-chemical products , or prob will/should be vs being used in this fuzzy 19ct herbalist manner . 
  still , occasionaly there can be a financial argument for such more primitive approaches . 
  there was recently ( ish ) a lecture on actual medical uses of cannabis as part of sceptics in the pub , organized by the society for promotion of science and critical thought in zagreb , croatia . 
  generated a lot of interest ( croatian-language youtube of it here : http://www.youtube.com/watch?v=j5iijdobpdi ) as the government has recently decided to allow medical cannabis for some such limited indications . 
  pretty informative ( and occasonaly funny ) on various effects and unknowns of effects of cannabis on neural subsystems , as well as presenting just such potential use-cases and their scientific support , and limitations of such support for various indications . 
  kako bi komunizam funkcionirao bez demokracije ? 
  you mean the hype cycle ? 
  the sad thing is how he references clearly interesting art as his counterexamples and calls for `` objective standards '' . . 
  but actually i think there is an interesting question about the nature of aesthetics ( and ethics , as these judgements seem similar ) . 
  no doubt tastes and favorites differ -- but is some stuff just trash , just kitch ? 
  not often would one consider so about classic paintings , but consider yet another cheesy sunset or cat picture or such in your social media stream ? 
  i have a feeling most would not be celebrated by a community of people that devote their lives to art , even if cute ? 
  not that this is a great definition , and certainly not about objectivity , but it does n't feel like artistic merit means really simply popularity or however uninformed personal preference . 
  anyhow , i do n't wan na try doing impromptu philosophy now nor do i have any position yet , but something puzzles me about these ( quasi ) normative statements ppl make say about music or art taste . . 
  well , guess i had experiences with deeper woo then , like ppl that claim it can cure cancers . 
  and even as therapy for a friend w schizophrenia , in some low doses , which sounded like a very bad idea to me . 
  thankfully , they did n't go through w that . 
  i think . . 
  i 'm really confused ; the sidebar claims this sub is for `` news , research paper , video , lectures , software and discussion on machine learning , data mining , information retrieval , predictive statistics , learning theory , search engines , pattern recognition and analytics '', 
  where among those does a `` discussion of nick bostrom 's book `` superintelligence '' . 
  the book has had an effect on the thinking of many of the world 's thought leaders . 
  not just in artificial intelligence , but in a range of different domains ( politicians , physicists , business leaders ) . '', 
  fit ? 
  seems to me this sub is starting to get spammed with r/futurology kind of content , or at least with general philosophical musings on the impact of ai that have no practical relation to actually doing , learning or research in machine learning, 
  in terms of general interest a crowd around here could have , sure - but as a reddit sub , i think its quality profits from a clear and narrow topic focus . 
  moreover it apparently already has just that , but perhaps the enforcement is too lax . 
  those are clearly philosophical concerns . 
  as far as i can see , this is n't a sub about philosophy . 
  scope there is broad and amorphous , and signal to noise ratio of the sub would suffer by such expansion . 
  i completely disagree that this sub should be about ethics of artificial intelligence . 
  as far as i can see by its self-description in fact , it just simply is n't . 
  thing is , its hard to expect a discussion of any quality in the ml community about rather general philosophical issues ppl have little knowledge of here ( edit myself included , certainly , despite a long-explored interest ) . 
  if nature of intelligence is a relevant topic , is n't it also the case with the nature of consciousness ( hell , a fair number of supposedly purely ethical concerns depend on assumptions on that front , as in what kind of unintended behavior of ai could be a product of its rationality and what constitutes unwarranted anthropomorphisation ) . 
  are n't we simply in the domain of psychology and the philosophy of mind here ? 
  idk , if i wan na talk chalmers and nagel and searle and dennett , i check out r/philosophy as i 'd expect better informed discussions . 
  there 's advantages to keeping largish subs tightly moderated to a clear norm even besides this , in moderation load , less possibility for subreddit drama etc. 
  consider places like r/askhistorians and your default shithole sub of choice and how the moderation is set up there . 
  at the very least , these are general issues about artificial intelligence , rather than ml specific , so would n't a closer sub then be something like r/artificial ? 
  yeah , i do realise the article itself is from a far more interesting source , still the topical fit seems a strech . 
  sidebar suggest a sub for general interest ai stuff could be r/artificial - why is that not a better fit ? 
   at the same time , you have to accept the fact that without the public ai hype this subreddit would not have as many engaged subscribers and active readers as it does have today . 
  this particular book plays a role in this hype , therefore a well written commentary on it does have some relevance to this communty . 
   in this case , we are talking about a post written by a well-regarded machine learning researcher , which contains some technical points about `` predictive statistics '' as well as clarifies some notions on objective functions in `` machine learning '' . 
  yeah , i guess that 's exactly what 's going on here . 
  ah , i 'd simply favor a narrower approach to sub 's management precisely because it seems to have significantly grown , as that can be the death to focus and quality of many a sub -- to keep ppl discussing only things they 're best at discussing well . 
  once you get to this soft/fuzzy philosophical envelope of any field , opinions are many but insight rare . 
  no , i completely agree - ethical implications of a field is a discussion that must be informed by actual scientific opinion on what these might be . 
  perhaps in nuclear physics that could be ( have been ? ), 
  nuclear weapons , and in ml concerns with privacy and perhaps employment etc ( though i would still wonder what the proper forum for such discussions is , since a sub could easily be swamped with low-quality discussions in that domain too ; fuzzy areas like this are abundant with opinions ) . 
  the discussion on what a superintelligent ai we have no architecture to discuss concretely might do in a number of decades is so far removed from the state of the art not to be at all comparable to any actual ethical dillemas of another field however , being limited to purely speculative reasoning that is really the proper domain of philosophy . 
  you ca n't expect that anything about approaches in the current field will necessarily even be relevant to it , so any extrapolation based on actual fact is barely better than just speculating w/o any scientific training . 
  ng compared it to the problem of overpopulation on mars , and it seems appropriate ; this is just like physicists working on propulsion systems or access to space discussing the ethical implications of such a scenario . 
  the author seems to be making a similar point about bostrom 's presumptions really - that even from the perspective of today 's state of the art , they seem so architecturally simplistic that any extrapolation he wants to make decades into the future is grossly unwarranted . 
  dennett would prob call it an `` intuition pump '' -- '' designed to elicit intuitive but incorrect answers by formulating the description in such a way that important implications of the experiment would be difficult to imagine and tend to be ignored . '', 
  such superficiality is then visible even to a modestly informed generalist in other ( more popular/influential ) examples . 
   it seems you are the one trying to move the discussion into the fields of philosophy and psychology , introducing unnecessary and not well defined concepts as consciousness . 
  oh , yeah sure ; that was just an example of what truly broadening the discussion to `` philosophical and , more importantly , ethical concerns '' can just as well entail - and hence post that would be in scope here as much as this one . 
  intelligence is not defined any more clearly in the mentioned fields , and you can see the author having to clarify his own definition on the start ( and in an uncommon way at that ) , so i do n't see how the line is drawn between the two . 
  more common questions are admittedly simply about the possibility of a human-like machine , as opposed to what happens if something like them is around - another indication of just how speculative this enterprise is . 
  but as to the connection i parenthetically made - consider the article itself ; it discusses the greek skeptics and contrasts it with a `` savant idiot '' ai model by bostrom - this is precisely the issue of what pure rationality could dictate an ai can do , as opposed to what motives ascribed to it would just be an anthropomorphisation . 
   bostrom suggests that due to uncertainty it would believe it might not have achieved its goal and continue to consume world resource in an effort to do so .13 in this respect the agent appears to be taking the inverse action of that suggested by the greek skeptic aenesidemus14 , who advocated suspension of judgment , or epoch\u00e9 , in the presence of uncertainty . 
  suspension of judgment ( delay of decision making ) meaning specifically ` refrain from action ' . 
  that is indeed the intelligent reaction to uncertainty . 
   this meme occurs through out the book . 
  the `` savant idiot '' ,15 a gifted intelligence that does a particular thing really stupidly . 
  as such it contradicts the concept of superintelligence . 
  the superintelligence is better in all ways than us , but then somehow must also be taught values and morals . 
  values and morals are part of our complex emergent human behaviour . 
  part of both our innate and our developed intelligence , both individually and collectively as a species . 
  they are part of our natural conservatism that constrains extreme behavior . 
  constraints on extreme behaviour are necessary because of the general futility of absolute prediction . 
  these are ( interesting ) aguments in metaethics and epistemology , and i do n't expect anyone in this crowd will be able to evaluate them , for here * they * do n't know what they 're talking about . 
  metaethical claim seems a bit obscure and is certainly presented dogmatically , while the epistemological one should be well-trodden territory , in bayesian epistemology at least . 
  anyhow the veracity of it is n't the point , but an illustration on why i would n't expect this place to be the best for a discussion of this kind . 
  machine learning is a subfield of ai - other subs already cater to such more general content , theoretically allowing this sub to be focused more precisely ; and clearly not everything a machine learning researcher blogs about is about machine learning -- in this case , the connection to any topics of this sub is tenous at best . 
  so it , along with anything not strictly related to the field should imho be simply moderated away . 
  largish subs typically require a more active moderation stance , lest they be drowned in rather empty discussions of barely related content , despite ( or even because of ? ), 
  the self-moderation by upvoting/downvoting . 
  and imho it shows in the discussions under this post nicely why ; plenty of opinions , and nothing really informative ... 
  edit : having an interest in the broad-strokes future of ai and its implications is very common , and having an opinion on the matter is cheap , being mostly unconstrained by data . 
  in consequence , what you have is highly engaging content of poor signal/noise ratio ; the kind that kills the quality of growing subs if it becomes too common . 
  / edit, 
  ah , i guess i just disagree on each point ; just yesterday i saw a number of r/futurology - like shitposts here , admittedly downvoted , but still on the front page , and would welcome agressive moderators to draw a clearly defined line . 
  as to the question itself , i neither expect nor see particularly insighful comments on it here , as opposed to asking the general public , given how speculative the matter is . 
  and moreover , i find it too remote to be even amenable to interesting answers yet , so not particularly urgent . 
  i gave a little bit more detail/argument in another post in this discussion : https://www.reddit.com/r/machinelearning/comments/4in9ub/neil_lawrence_on_bostroms_superintelligence/d306eii, 
  well , as to the timescale , i did n't mean to make a personal prediction there - this was simply the scale discussed by lawrence and bostrom ( i only mentioned decades while describing what this particular discussion is about ) , so uncontroversial merely in this narrow discussion :, 
   it is important to bear in mind that bostrom is worried about the effect of intelligence on 30 year ( and greater ) timescales .
