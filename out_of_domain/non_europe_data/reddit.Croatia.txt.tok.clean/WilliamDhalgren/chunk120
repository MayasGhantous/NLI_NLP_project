  i still care about sulu a lot though ; there was a period in my life with no internet access and a box of the original series dvds ; by the umpteenth watching , i could remember everything about the episode within seconds of its start . 
  and while i watched all ( pre-reboot ) star trek , i do n't even consider myself a fan ; the franchise is overall very spotty imho . 
  really disliked the reboot so stopped , but that 's an unrelated story . . 
  so , u/clunk00777 could you clarify re takei 's comment on sulu suddenly being gay ? 
  ofc the character was n't overtly gay in the series ; but do you have a source to him being actually surprised and against making him gay ? 
  cuz i have a vague memory of him maybe making the opposite comments ; i do n't know how to dig this up , but takei 's narrating about sulu in relation to his gayness , as we 're seeing those scenes where sulu 's shirtless with a sword ... 
  ofc it has been quite a few years since my tos marathons ; is there a canon reason to positively reject sulu being gay , or just naturally no overt support for it ? 
  indeed . 
  jos da nema ni dna ni poteza za zaplivati ... moga sam sidit u klimi doma a ne trpit to jebeno sunce onda . 
  al ko oce ... 
  i thought the charges against the guy were rape ? 
  well , ne izgleda vjerojatno da ce eu skoro zabraniti geoblocking , iako ima nesto pritiska za tim ; dosta se para vrti u industriji na davanju licenci teritorij po teritorij . 
  wait , is it ? 
  were n't there modified t-cells trials around in cancer and i think hiv therapies ? 
  for eg , https://www.theguardian.com/science/2016/feb/15/cancer-extraordinary-results-t-cell-therapy-research-clinical-trials, 
  edit : maybe the novelty is doing it with crispr here ? 
  well if you 're into classical music , there 's really tons of brilliant religious music . 
  bach 's cantatas or his b-minor mass come to mind first , but there 's really tons . 
  if anything that bugs me the most about `` christian '' music . 
  you have cheesy shit getting played on the christian radios ( mostly heard some catholic ones ) , while they could be educating the audiences with , for example , someone of the calibre of olivier messiaen , a deeply religious catholic , writing some of the best and most influential modernist works . 
  like a massive work `` the transfiguration of our lord jesus christ '' or the opera saint fran\u00e7ois d'assise ( or `` twenty contemplations on the infant jesus '' , or `` the nativity of the lord or the birth of the saviour '' etc etc ), 
  the film is certainly quite flawed , but lynch is imho quite good at the surreal , alien , noir-baroque atmosphere and aesthetic of it . 
  it still has amazing visual power , even while looking cheap and like 20 years older than it is . 
  the series on the other hand is just - fine . 
  not bad per se , not doing the mistakes of the film as badly but - sadly , forgettable . 
  this imho makes the film a far greater work . 
  i found ex machina rather cringe-worthy if anything . 
  its one thing to be as predictable as that film , or to offer as little in terms of either thought or entertainment , but quite another to also be that pompous and ignorant as the screenplay writer must have been to butcher mary 's room argument as badly as it was in that film . 
  yeah , you need to presume both that decoherence miraculously is avoided in such a huge messy biological system - something that 's technically difficult to do while allowing for computation , for but a number of atoms in our best controlled environments - but moreover also that interpretations of quantum physics are significantly wrong , else its quantumness does n't offer more than a boost in computing a limited subset of algorithms ( bqp ) and still does n't allow for computability beyond what a turing machine could ultimately do , bqp not likely to even be np-hard ( anymore that p already is likely to be so that is ) , let alone so far beyond it in the complexity hierarchy . 
  that 's why you have post-quantum public key cryptography being based on np-complete problems . 
  if you look at penrose 's arguments for example , he speculates about an objective collapse interpretation of quantum mechanics , where the collapse is a true physical - and moreover , gravitational - phenomena , to get much out of the pile of assumptions about possibility of relevance of quantum phenomena for neural processing . 
  this is squarely in the domain of philosophy , not science . 
  the real alternative remaining in contrast to the physical possibility ( which is a bit different that what 's usually considered in terms of software simulation ) of a brain in a box really just is - pixie dust in the synapses , as patricia churchland quipped . . 
  this really is n't the weakest point of the argument above anyhow ; afaik nanoscale engineering today does n't even suggest creating self-replicating machinery ; it being rather pointless economically and moreover potentially dangerous . 
  what is considered are industrial machines with nanoscale manufacturing capabilities , at some point in the future at least . 
  doing brains in boxes ( and if i might add , or nanoscale manufacturing ) could however be as remote a problem as is overpopulation on mars , as the ai researcher andrew ng phrased it . 
  so clearly sf , as you say . 
  do you mean the truenorth chip ? 
  that 's so extremely far away from any level of biological plausibility ( fascinating architecture though ) - no models that are used in computational neuroscience would run on it ; hell , its connection weights are just binary !? 
  and it does n't learn , hebbian-like or otherwise !? 
  making even a machine-learning style artificial neural net with that is dubious ( well , there was some recent work by bengio 's group on binarisation but certainly not what the sota of the field generally does ) , let alone something on the lines of a hodgkin -- huxley neuron . 
  ja bi ga osobno rezervirao za eventualne buduce teske . 
  huh ? 
  that 's just regular timing-sensitive spiking neuron modeling ; nothing the least low level ; no synapse modelling , certainly no care for protein folding , let alone anything quantum ; just your basic electrical model . 
  guess you might mean a slightly simplified derivative like say izhikevich instead -- but this changes absolutely nothing in what i said ; truenorth is so unsuited for such a model too , that its not worth making a distinction . 
  what substantially simplified in comparison to this has been used in actual computational neuroscience , that you could 've meant when mentioning truenorth as a possibly brain emulation device ? 
  its death +70 if there 's an author , or 120 from creation or 95 from publishing , whichever is shorter , if its work for hire ( like movies , tv ), 
  nuts . 
  why would the setting with constrained resources particularly help the series ? 
  its a mostly episodic series and as such i thought , would probably prosper or fail on the quality of the sf stories writers make for that universe , more than anything particular about the settings ; just like tng or tos did . 
  and yeah , the writing in star trek has imho been rather poor for many years now , including most of voy . 
  this year 's wmt machine translation competition seems to have been dominated by neural machine translation approaches , so thought maybe this sub would enjoy the slides with a short overview , from the team that did best in most language pairs ( u. edinburgh ) . 
  paper on their system for ( a bit ) more meat : http://www.statmt.org/wmt16/pdf/w16-2323.pdf, 
  but that does n't do the task at all ; its supposed to take an order via tablet , make the required number of bratwursts , and deliver them to the plate . 
  could one do that w/o a robotic arm ? 
  the off-the-shelf robot they 're using is about 45000 $ according to http://spectrum.ieee.org/automaton/robotics/industrial-robots/universal-robots-ur3-robotic-arm not sure if they could downscale it a bit ( eg , a baxter has half the price , and there are cheaper models from universal robots too - i 'm guessing they just used the arm they had for the demo , rather than actually needing the performance ) - but anyhow easily cheaper if it can be truly autonomous than any machine requiring human intervention in the order delivery process . 
  i should 've linked the conference page proper , then : http://www.statmt.org/wmt16/ - they 're under papers w decent titles and you also have links to past conferences . 
  there 's also the evaluation matrix http://matrix.statmt.org/, 
  as to the exact language choices - i do n't really know , sry ; but i 'll speculate a little bit here ;, 
  the language pairs are n't fixed but change over the years ; though most years its the best-working and/or highest-resource pairs ie english to/from german , french , spanish plus czech , and also plus an extra low resource language in recent years . 
  last year there was no spanish , but finnish was added . 
  the year before , spanish was also missing , but the low resource language was hindi . 
  this year there 's not even french , adding turkish and romanian and extra in the 2 specialized-fields tasks . 
  some other years , they did hungarian , italian , even haitian creole . 
  training resources probably skew the competition towards european pairs , since they take advantage of the paralel corporas from the european parliament , and also perhaps the fact it is funded by the eu . 
  yandex apparently gave them russian corpora , and uni helsinki the finnish . 
  german 's an interesting problem , since sota is n't great and yet its a high-resource language , and czech has a very strong team with a unique approach - tectoml is a deep syntax transfer-based machine , later used as a hybrid system in combination with regular moses for consistently better results than what classical phrase-based systems could do . 
  until this year at least , when neural approaches became even stronger . 
  bengio 's team from last year heralded this development i guess by being strongest by a fair margin in the en-de pair with a neural approach . 
  finnish is quite a challenge both as a language and in terms of its resources . 
  phrase-based approaches have n't generally handled languages with rich morphologies nearly as good as those with modest or minimal ones , so things like czech , russian , german , finnish are a strong challenge . 
  i have seen papers certainly on chinese ( and wonder how come it was never part of wmt as well ) , yes ; say recently this one https://arxiv.org/abs/1607.01856 and there 's this recent competition for english to/from arabic and chinese http://www.nist.gov/itl/iad/mig/openmtchallenge15.cfm should dig for the paper list but this is one of the groups on the arabic task https://arxiv.org/abs/1606.05759, 
  i 'd have nothing but google to seek korean and japanese papers , sry . 
  a guess at a possible answer - agda and coq are focused on being great proof assistants ; a slightly different usecase . 
  agda less so , but certainly has the same issues as idris as discussed below :, 
  idris could do it sure but seems comparatively grossly immature -- haskell has a larger community , ecosystem , more mature infrastructure and appears so closely a related language design anyhow that merely waiting a few years for full dependent typing to be sorted out seems hardly worth switching languages . 
  as if there is just that one point in possible design space . 
  this is not what haskell intends to be ;, 
   languages such as coq and agda avoid the, 
  axiom because, 
  it introduces inconsistency , but that is not an issue here . 
  the fc, 
  type language is already inconsistent in the sense that all kinds, 
  are inhabited . 
  the type safety property of fc depends on the, 
  consistency of its, 
  coercion, 
  language , not its, 
  language . 
   if a consistent type language were desired for fc for other reasons , we be -, 
  lieve that the ideas presented in this paper are adaptable to the stratification, 
  into, 
  universe levels, 
  ( luo 1994 ) , as is done in coq and agda . 
  haskell is n't a system f_omega , but system fc , system f with first-class type equality proofs : coercions . 
  the only thing fc was designed for was for - haskell . 
  and it is n't likely to want to use a vanilla dependently-typed caclulus any more it wanted a regular f-omega either . 
  it is an inherently inconsistent logic with a type-in-type axiom ( but nevertheless preserving type-safety - while in a traditional calculus it would make typechecking undecidable ) , with decidable and syntax-directed type checking . 
  power-to-weight of this approach seems most appealing , and the details of its construction are but a technicality to ensure decidability of typing in the face of inherent inconsistency of haskell as logic . 
  this is how the autors of the current core see where it currently stands :,
